# atlasEuropa
*A project on using deep learning to map land cover and land use in Europe.*

*Topic: Convolutional Neural Networks applied to Sentinel-2 images for multi-class classification, trained to track Land cover - Land use over 34 European coutnries.*

*Module 4 project for FlatIron School Data Science course*

## Project structure
├── LICENSE
├── README.md                                                <- The project layout (this file)
├── data
│   ├── images                                                   <- For README.md, presentation
│   ├── jpg                                                        <- Training, validation and test set with jpg images
│   ├── tif                                                          <- Training, validation and test set with tif images
│   └── raw                                                         <- The original, immutable data dump
│
├── load_eda_train.ipynb      <- Input, training, validation, test, reports
├── utils.py                           <- import libraries and utility functions
│
├── reports                              <- Reports and presentations
│   └── presentation.pdf         <- Non-technical presentation
│   └── assets                         <- Plots
│   └── logs                             <- Tensorboard logs
│   └── saved_models             <- Saved models
│   └── maps                           <- Folium map in HTML

└── requirements.txt                <- The requirements file for reproducing the analysis environment


## Project description
Remote sensing data offer a low cost, scalable, tool to analyse geophysical and geospatial phenomena, with high level of accuracy, coherence, and richness in terms of diversity of data, in particular if we consider, i.e.,  multi or hyperspectral imaging, as well as LiDAR and SAR, which translates in significant business opportunities. The fields of application goes from agriculture, to fisheries production, forestry, resource management, risk and anomaly prediction, disasters management, urban planning, mobility and so on. 

When talking about remote sensing data, from now on I'll refer specifically to images (multi-spectral and hyperspectral). RS data is characterized by size (which is big, TB), dimensionality (image size and number of channels/bands), and other peculiarities that requrie specific pre-rpocessing and post-processing techniques. Machine learning has been extensively applied  to  remote sensing data, however it is only recently that the most recent advancements in machine learning for computer vision, specifically deep learning,  have been adopted. The lack of huge, labelled datasets and the computational requirements to process very large images, have been bottlenecks to the field. 

Within this context, as part of my educational path at Flatiron School - Data Science, for my fourth portfolio project the prescribed task is to output a proof of concept of a selected technique. I wanted to learn and develop deep learning models able to do automated classification of Remote Sensing (RS) imagery according to land use to 1) help us to track and, hopefully, plan solutions to unsustainble human damages to ecosystems; 2) help us building a log of land use/land cover for locations; 3) measure the results of conservation or encroachments. This is my first project using deep learning, and my first project on RS imagery.

The project structure was developed using the well-known OSEMiN methodology. The business understanding section summarises the importance and the economical opportunities related to land cover/land use classification. Although it is a proof of concept, what I wanted to achieve with this project was being able to answer to the following: 1) Can deep learning help updating an atlas of LULC? 2) Can this project potentially help tracking changes in LULC? 3) Is it possible to train an accurate deep learning model for LULC with a small-to-medium sized dataset?

## Business understanding
### Remote sensing data and land use/land cover (LULC): a brief introduction
In order to understand properly the use of satellite images, it is necessary to explain the basic principles of remote sensing, which can briefly be summarized as follows. Earth's surface is illuminated by a wide spectrum of electromagnetic radiation coming from the sun. All objects on Earth's surface (targets) are interfering with radiation as targets reflect, transmit, or absorb the incoming electromagnetic waves. The process that takes place depends on the physical and chemical structure of the target and on the wavelength involved. The reflected part of the spectrum is the most important for remote-sensing applications dealing with land. Over the different wavelengths, targets reflect in a specific, and in some cases unique, way. This characteristic spectral response of objects enables their identification by means of remote sensing. Comparing the response patterns of different features of Earth's surface in different spectral ranges makes the different objects distinguishable. I.e. chlorophyll strongly absorbs radiation in the red and blue wavelengths but reflects green wavelengths. Therefore, leaves appear green in the summer, when their chlorophyll content is at its maximum. In autumn, there is less chlorophyll in the leaves, so there is less absorption and proportionally more reflection of the red wavelengths, making the leaves appear red or yellow. The internal structure of healthy leaves acts as a strong reflector of near-infrared wavelengths. The near-IR/red ratio is the basis for many vegetation indices, used for vegetation monitoring. The specific reflection properties of each plant enable the identification and differentiation of different plants. Water absorbs the longer wavelengths in the visible range and the near infrared radiation more than shorter visible wavelengths. Thus, water typically looks blue or blue-green due to stronger reflectance at these shorter wavelengths, and darker if viewed at red or near infrared wavelengths. If there is suspended sediment present in the upper layers of the water body, then this will allow a better reflectivity and brighter appearance of the water. The reflection patterns of soils exhibit stronger spectral features. The reflection depends mainly on the mineral composition, the grain size, the water, and the organic content of the soil. The drier, purer soils have a lower emission in this range of the spectrum.
### Copernicus data and business opportunities: a brief overview
Land-cover and land-use information are required for many different kinds of spatial planning, from urban planning at a local level up to regional development. They play an important role in agricultural policy making. Moreover, land-cover data are used as basic information for sustainable management of natural resources; they are increasingly needed for the assessment of impacts of economic development on the environment. Hence, they are fundamental for guiding decision making at various geographical levels. Various tools and methods for collecting land-cover and land-use information have been developed to satisfy the user requirements and the information demand. The European Union and the European Space Agency (ESA) launched Copernicus program to boost Earth observation data analysis adopting an open-data policy. Under this program, ESA operates a series of satellites known as Sentinels. The range of applications of Sentinels data is wide as it goes from food, agriculture and fisheries, to biodiversity and enviornmental protection, climate, water and energy, territorial management and urban planning, civil protection, transports, civil infrastructures and safety, and finally public health, cultural heritage, tourism and leisure. The purpose of this very brief buisness opportunities review is not to do an in depth analysis of all sectors, rather it has to been seen as a framework to highlight and understand the reasons behind choosing this topic for my project. I.e. let's take the case of agriculture, fisheries and aquaculture. They are some of the pillars of the economic structure of the European Union. EU is the fifht largest producer in terms of fisheries and aquaculture production. 85% of land cover in European Union is constituted by agricultural land and forests. Resource managment is critical to sustainability, and ultimately, well being of countries. Tracking this vast and diverse region is key but challenging. To take decisions it is essential to have low cost, accessible, scalable, accurate, diverse and updated levels of information.

An example of significant strategic importance is reflected by the Common Agriculture Policy (CAP), one of the most prominent and oldest EU policies, with the biggest share of EU spending (about 40% in 2016). In many countries, the “second pillar” of the CAP (rural development programme) is implemented at regional level and, because of the impact on their territory, almost all regional administrations have this competence in their scope. Data from the Sentinel-1 and Sentinel-2 satellites can support the setup of more efficient and environment-friendly agricultural practices for public authorities, companies and farmers alike. The system for the management and control of payments to the farmers is called the Integrated Administration and Control System (IACS) . IACS includes a computer database for storing all agricultural areas eligible for a direct payment in a Member State. This database is called Land Parcel Identification System (LPIS). LPIS ensures that the payments are distributed according to the correct area of the parcels. LPIS contains geo-referenced polygons of land parcels (later parcels), land cover information as well as the identifier of the crowing crop in each parcel among with other information. The parcel geometries are digitized, and the parcel information is announced by the farmers when applying for the subsidies. In order to ensure that the subsidies are divided equally and without misuse, the CAP subsidies must be controlled by the local authorities within IACS. At least 5% of the agricultural parcels, that the subsidies are applied for, have to be monitored for each year. Until now the monitoring has been done by visiting the farms or manually studying ortophotos or using other similar methods. In 2014 European Comission regulation No. 807/2014 the new technologies are suggested to be used for the control. One of the suggested methods is the monitoring using Remote Sensing (RS) imagery. As we can see, Land Use/Land Cover (LULC) mapping is a key building block in the value chain provided by remote sensing data. It can be seen as one of the first steps to more advanced and insightful analysis leveraging on remote sensing data. As a proof of concept, with this project we want to address the following questions:

1) Can deep learning help updating an atlas of LULC? 2) Can this project potentially help tracking changes in LULC? 3) Is it possible to train an accurate deep learning model for LULC with a small-to-medium sized dataset?

## Related work 
### Classification methods in Remote Sensing for LULC
Machine learning has been widely adopted for decades for this purpose, however deep learning, a sub-field of machine learning, hasn't been extensively applied to remote sensing data, yet. Traditional machine learning algorithms require significant human experience and prior knowledge to select the features for modeling,  with no guarantee that the best set of features is actuallly selected for a given task. In contrast, deep learning dclassification architectures have feature extraction capability by design. Deep learning methods are able to learn complex representations and non linear relationships among features, without requiring an extensive, prior domain knowledge on the data. Indeed, the advantages introduced with deep learning solutions lie in the automatic and hierarchical learning process from data itself. Nowadays CNNs are the most popular deep learning approach in computer vision, thanks to their ability to learn space-invariant features. They can also work with a limited training dataset thanks to new and powerful regularizationmethods.

Multi-spectral images are arrays of X rows, Y columns and P spectral channels (bands). CNNs are designed to process data in the form of multiple arrays. Just to mention a few of the recent, most famous, CNNs architectures: AlexNet, VGGNet, ResNet, DenseNet, Inception.

A CNN consists of series of layers. Feature extraction occurs in convolutional layers, which consist of convolving inputs with a set of filters followed by an activation function to add non-linearity. The first convolutional layers capture lower level features (i.e. edges) whereas the deeper layers extract more abstract and complex features by combining low-level layers. In order to reduce the number of training parameters, computational cost and overfitting, after a certain number of convolutional layers, pooling layers are another key component of CNNs. Overfitting, hence generalization, can be achieved using regularization layers (i.e. L1 and L2 regularization) and dropout layers, by randomly subsampling the outputs of a layer. Another key component of CNNs are normalization layers. By normalizing inputs after a convolutional layer or a fully connected layer before the activation function, normalization layers prevent instability and vanishing/exploding gradients, although, as many things in deep learning, recently it has been proved that actually using batch normalization after the activation, togheter with dropout layers helps achieving better performance. Finally, the 'head'of a CNN is usually some fully connected (FC)  layers with a final FC as a classifier.

RS imagery classification evolved from single-pixel paridigm to objects, and finally to semantic-level. The first paridgm in RS imagery classification was at single pixel level. There are mainly three classification methods, depending on the features used: 1) handcrafted feature based methods; 2) unsupervised feature learning based methods; 3) deep feature learning based methods.

Depending also on the type of remote sensing data (i.e. raster, multi-spectral, hyperspectral, LiDAR, SAR etc.) , several techniques have been developed to inlcude/exclude spatial and spectral information, tackling the problem at three stages: pre-processing, modelling, post-processing. A full review can be found here. In general,  jointly considering spectral and spatial features has been proven to enhance the classification, therefore we're going to test this creating two different pipelines: one with raster (jpg) and one with multi-spectral images (tif). It is not only possible but actually advisable, especially for small datasets and strong computational limitations, adopting deep transfer learning techniques,  consisting in using existing CNNs, for scene classification of remote sensing images. The success of this approach depends on several factors, the most important one being the similarity between the original task on which the CNN was originally trained and the target task. I.e. using CNNs trained on the ImageNet dataset for raster RS imagery makes sense due to low-level similarities with general-purpose images. On the other hand, the same would not apply to SAR (radar) images due to their peculiar pixel-level statistics. Transfer learning applied to multi-spectral images is less straightforward as pre-trained models are trained on datasets such as ImageNet that are rgb. In order to leverage on pre-trained models, pre-processing techniques such as PCA or more in general dimensionality reduction, are usually adopted. Other techniques use greyscale, single band images as input features. The three main trasnfer learning strategies are: full training, fine tuning, and feature extraction. Feature Extraction consists in using features learned by a previous network, removed the classifier layer, to detect features from new samples, by adding a new classifier, that will be trained from scratch, on top of the pretrained model (i.e. a linear classifier, SVM etc.). Therefore, retraining the entire model is not needed. Fine-Tuning consists in de-freezing some of the layers of a pre-trained network, adding a new classifier on top and train/fine-tune the weights of the trainable layers. This allows us to "fine-tune" the more abstract  feature representations on the specific target task. Experimental results show that fine tuning tends to be the best performing strategy on small-scale datasets.

However, this approach is valid only when selecting 3 bands, as existing and publicly available, pre-trained models are based on  databases like ImageNet, therefore, it shouldn't be applied to multi-spectral images. Training a model from scratch on high dimensional images (10 channels) as in the case of multi-spectral imagery, require usually complex architectures and high computational power.

I had two main constraints to take into account : the model should be trainable at max overnight and my computational power is very limited (no GPUs, only my MacBook pro 17"from mid 2015). 

A solution investigated by Senecal et. al should tackle specifically this issue: how to train an efficient model using multi-spectral images for land us/land cover. They implemented a variation of SqueezeNet, called SpectrumNet. Their code is not publicly available, however implemented it from scratch based on their paper. SqueezeNet has the peculiarity to be very efficient in terms of accuracy density, which fits our purposes, as discussed here. My results, unfortunately don't confirm the results shown in the paper, as the net performs dramatically worse than expected. Further investigations would be required.

The loss function considered was categorical crossentropy, which is common and appropriate for multi-class classification. The target metric is categorical accuracy, as the dataset is only slighlty unbalanced. 

## Dataset
![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png "COUNT PLOT OF NUMBER OF IMAGES PER LABEL")
FIG : COUNT PLOT OF NUMBER OF IMAGES PER LABEL

![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png "CO-OCCURENCY MATRIX FOR ALL LABELS")
FIG : CO-OCCURENCY MATRIX FOR ALL LABELS

The dataset is called EuroSat, based on Sentinel-2 satellite images covering 13 spectral bands and consisting out of 10 classes with in total 27,000 labeled and geo-referenced images from 34 countries in Europe, as shown in the map below. The dataset is slighltly unmbalanced, with the label 'pasture'as the one with fewer samples. It cannot be considered as a big dataset, rather a small-medium sized one. This poses challenges in terms of achievable performances using CNNs, especially considering that transfer learning using ImageNet weights is not directly applicable to multispectral images. Whereas to load the jpg files I used Keras ImageDataGenerator along with flow_from_dataframe, for the tif images, I first created a dataset of numpy arrays, pickled it, and then after loading it, I used ImageDataGenerator with .flow method. In the future, I want to use lower level Tensorflow to handle tif images and jpg images in a more efficient way. 

Preprocessing consisted in rescaling and data augmentation for jpg images, whereas I filtered out those bands used for atmospheric studies only, then I normalized all the remaining bands (10), and finally I applied some data augmentation to reduce overfitting and help generalization. When using pre-trained models and jpg images, I didn't apply rescaling as I adopted, as suggested by Keras official page, ResNet preprocess_input method. 

Sentinel-2A is one satellite in the two-satellite constellation of the identical land monitoring satellites Sentinel-2A and Sentinel-2B. The satellites were successfully launched in June 2015 (Sentinel2A) and March 2017 (Sentinel-2B). Both sun-synchronous satellites capture the global Earth’s land surface with a Multispectral Imager (MSI) covering the 13 different spectral bands listed in Table I. The three bands B01, B09 and B10 are intended to be used for the correction of atmospheric effects (e.g., aerosols, cirrus or water vapor). The remaining bands are primarily intended to identify and monitor land use and land cover classes. In addition to mainland, large islands as well as inland and coastal waters are covered by these two satellites. The two-satellite constellation generates a coverage of almost the entire Earth’s land surface about every five days, i.e. the satellites capture each point in the covered area about every five days. This short repeat cycle as well as the future availability of the Sentinel satellites allows a continuous monitoring of the Earth’s land surface for about the next 20 - 30 years. Most importantly, the data is openly and freely accessible and can be used for any application (commercial or non-commercial use). The large volume of satellite data in combination with powerful machine learning methods will influence future research.

## Methods
I approached to this project with the idea of maximising learnings on deep learning, tensorflow, and remote sensing. Trades off were necessary due to time constraints and priorities, I used Keras API ImageDataGenerator, to feed the training. Eager execution was active, as this project is not meant to go into production. No GPUs or TPUs were used for training or prediction. I started  experiments with jpg images first, and then moved to use SpectrumNet for multispectral images.

I first tried with training from scratch variations of a cascade architecture (VGG inspired), with an increasing number of layers and complexity. I iterated with a low number of epochs (4) while tuning batch size, percentage of downsampling the full dataset and data augmentation. I moved to using a pre-trained model (ResNet50), using ImageNet weights, with a GlobalAveragePooling layer, a dropout layer and  a final classifier consisting of 10 neurons with sigmoid activation. This architecture was taken from Keras ResNet official page. I chose ResNet50 (the smallest of the ResNet family) as it is a good trade off between computational complexity and accuracy. I started experimenting with transfer learning first using ResNet50 as a feature extractor, then fine-tuning, incresingly defreezing the number of trainable layers. Finally, I used L2 regularization to prevent overfitting. Methodologically, I took decisions on how to improve performance based on two graphs: loss curves and categorical accuracy curves for training and validation sets. Loss curves were prioritized as categorical accuracy is a metric related with thresholds, rather than actual proabilities.

Due to computational and time constraints, I downsampled the original dataset to 30%, with a number of epochs equals to 4. Finally, once I found the best configuration, I trained on the full dataset. Train-test split ratio and train-val ratio were respectively 0.9 and 0.8. Train, validation and test sets were obtained with random shuffling and sampling. Distributions show that validation and test sets are representative of the initial sample distribution in terms of labels. I didn't use cross fold validation due to time constraints, and because, as explained by Andrew NG in his course specialization on Deep Learning on Coursera, crossvalidation is usually unfeasible (as in my case as well).

The hyperparameters tuned were: number of epochs: 4; number of layers; learning rate: 10ˆ-4 with ReduceLROnPlateau callback to 10ˆ-6; L2 regularization layer: l2 regularization factor 0.0001 applied to all layers (where applicable) of ResNet base model.


## Results
1. Can deep learning help updating an atlas of LULC?
The potential of automated mapping can be summarised by the accuracy of more than 95% that our model reached. This means that, hypotetically, scaling it up to the entire European region, we could map each tile land use and land cover, obtaining an atlas that could be updated throughout time. This is significant as we are able to have a ground truth of the status and the evolution of a region, and do analysis on, i.e., the effectiveness of certain policies or how to sustainable use resources. At the same time, it is interesting to see how the model confuses similar patterns. For example, it misclassify rivers as highways and viceversa. Or industrial vs residential areas, or sea lakes vs large rivers, forests vs herbaceous areas. This would suggest specific strategies to tackle similar objects, such as specialised classifiers.

2. What are the requirements for generalising this proof of concept?
This project however is not able to map parcels to create a database useful for the Common Agriculture Policy. It can be seen, however, as a prototype of how to implement a possible solution. What we would require is to train our model on different crop types, throughout the year, so to be able to map out Euorpe’s lands parcels automatically.

3. Is it possible to train an accurate deep learning model for LULC with a small-to-medium sized dataset?
One of the peculiarities of deep learning is the need of huge amount of data to obtain accurate predictions. With satellite images, this is far from easy, as w.r.t. to other fields, there aren’t huge freely available, datasets. Building a big dataset from scratch can be very expensive, limiting from the beginning the development of techniques such as deep learning in certain fields. However, this project demonstrates that it is actually possible to obtain 95% accuracy with a small-to-medium sized dataset, making it interesting from a cost-efficiency point of view.

## Future works and conclusion
First, at the beginning of this project, we wanted to leverage the power of multispectral data. Unfortunately, multispectral data require specific architectures, which we would love to investigate in the future.

Second, leveraging on different data sources could allow us to tackle multi-disciplinary problems, i.e. deforestation. So on one hand we could track the land use and land cover of an area at risk of deforestation throughout time, and on the other one we could infere on how the presence of human activities (i.e. commodities production) influence on the land cover changes.

Finally, we would love to put this tool into production.

This project investigated as a proof of concept, how and if deep learning can be applied to map land use and land cover in Europe to create an atlas, in other words, a database. We saw a map showing the potential of automated mapping, then we moved to understanding the requirements for generalising its application and finally we proved how it is possible to obtain a tool that has an accuracy close to the state-of-the-art without a huge and expensive dataset.
