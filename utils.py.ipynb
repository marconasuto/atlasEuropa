{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T14:52:29.086482Z",
     "start_time": "2021-05-29T14:52:23.076223Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "from skimage import io\n",
    "from spectral import *\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.coords import BoundingBox\n",
    "from rasterio import windows\n",
    "from rasterio import warp\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import folium\n",
    "import branca\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import shutil\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import MultiLabelConfusionMatrix\n",
    "import cv2\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, concatenate, Dropout, Flatten, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import get_source_inputs\n",
    "from tensorflow.keras.utils import get_file\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:23:57.687317Z",
     "start_time": "2021-05-28T17:23:57.683757Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:23:58.550574Z",
     "start_time": "2021-05-28T17:23:58.546749Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_channels(string):\n",
    "    '''Channels selector:\n",
    "       Input: 'all' or list among following: 'Blue', 'Green', 'Red', 'Red edge 1', 'Red edge 2', 'Red edge 3', 'NIR', 'Red edge 4', 'SWIR 1', 'SWIR 2'''\n",
    "\n",
    "    channels = []\n",
    "    if string == 'all':\n",
    "        channels = list(np.arange(10))\n",
    "    else:\n",
    "        _dict = {\n",
    "            'Blue': 0,\n",
    "            'Green': 1,\n",
    "            'Red': 2,\n",
    "            'Red edge 1': 3,\n",
    "            'Red edge 2': 4,\n",
    "            'Red edge 3': 5,\n",
    "            'NIR': 6,\n",
    "            'Red edge 4': 7,\n",
    "            'SWIR 1': 8,\n",
    "            'SWIR 2': 9\n",
    "        }\n",
    "        channels = list(map(_dict.get, string))\n",
    "\n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T09:20:24.019347Z",
     "start_time": "2021-05-29T09:20:23.998952Z"
    }
   },
   "outputs": [],
   "source": [
    "def params(\n",
    "        extension,\n",
    "        epochs,\n",
    "        pcg_dataset=1,\n",
    "        batch_size=128,\n",
    "        size=64,\n",
    "        parse_bands_verbose=False,\n",
    "        inspect_raster=False,\n",
    "        channels='all',\n",
    "        preprocess=False,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        rotation_range=0,\n",
    "        shear_range=0,\n",
    "        seed=random.seed(123),\n",
    "        columns=[\n",
    "            'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',\n",
    "            'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River',\n",
    "            'SeaLake'\n",
    "        ],\n",
    "        loss_type='categorical_crossentropy',\n",
    "        opt_type='Adam',\n",
    "        learning_rate=1e-4,\n",
    "        momentum=0.9,\n",
    "        regularization=False,\n",
    "        rlronplateau=False,\n",
    "        checkpoint=True,\n",
    "        no_imbalanced=True,\n",
    "        trainable='Full',\n",
    "        pcg_unfreeze=0,\n",
    "        data_path='./data',\n",
    "        reports_path='./reports',\n",
    "        tif_path='./data/raw/eurosat/ds/images/remote_sensing/otherDatasets/sentinel_2/tif',\n",
    "        jpg_path='./data/raw/eurosat/2750'):\n",
    "    ''' extension: jpg or tif\n",
    "        channels: 'all' means all channels in reference table;\n",
    "                     as alternative, select channels by name, i.e.:\n",
    "                     \n",
    "                     channels = ['Blue','Green', 'Red', 'NIR', 'SWIR2']\n",
    "                     \n",
    "                                B02 - Blue         10          490\n",
    "                                B03 - Green        10          560\n",
    "                                B04 - Red          10          665\n",
    "                                B05 - Red edge 1   20          705\n",
    "                                B06 - Red edge 2   20          740\n",
    "                                B07 - Red edge 3   20          783\n",
    "                                B08 - NIR          10          842\n",
    "                                B08A - Red edge 4  20          865\n",
    "                                B11 - SWIR 1       20          1610\n",
    "                                B12 - SWIR 2       20          2190 '''\n",
    "\n",
    "    raw_data_path = os.path.join(data_path, 'raw')\n",
    "    data_path_jpg = os.path.join(data_path, 'jpg')\n",
    "    data_path_tif = os.path.join(data_path, 'tif')\n",
    "    processed_path = os.path.join(data_path, 'processed')\n",
    "    eurosat_path = os.path.join(raw_data_path, 'eurosat')\n",
    "    assets_path = os.path.join(reports_path, 'assets')\n",
    "    pickled_tif_path = os.path.join(processed_path, 'tif')\n",
    "    reprojected_path = os.path.join(processed_path, 'reprojected')\n",
    "    reprojected_path_tif = os.path.join(reprojected_path, 'tif')\n",
    "    reports_maps_path = os.path.join(reports_path, 'maps')\n",
    "    reports_map_eda_path = os.path.join(start_params.reports_maps_path, 'eda')\n",
    "    reports_map_classifier_path = os.path.join(start_params.reports_maps_path,\n",
    "                                               'classifier')\n",
    "    train_data_dir_jpg = os.path.join(data_path_jpg, 'train')\n",
    "    val_data_dir_jpg = os.path.join(data_path_jpg, 'val')\n",
    "    test_data_dir_jpg = os.path.join(data_path_jpg, 'test')\n",
    "    train_data_dir_tif = os.path.join(data_path_tif, 'train')\n",
    "    val_data_dir_tif = os.path.join(data_path_tif, 'val')\n",
    "    test_data_dir_tif = os.path.join(data_path_tif, 'test')\n",
    "    log_folder = os.path.join(reports_path, 'logs')\n",
    "    log_gradient_tape_path = os.path.join(log_folder, 'gradient_tape')\n",
    "    log_cm_path = os.path.join(log_folder, 'cm')\n",
    "    weights_path = os.path.join(data_path, 'weights')\n",
    "    num_classes = len(columns)\n",
    "\n",
    "    channels = select_channels(channels)\n",
    "\n",
    "    if extension == 'jpg':\n",
    "        num_channels = 3\n",
    "    elif extension == 'tif':\n",
    "        num_channels = len(channels)\n",
    "    else:\n",
    "        print(\n",
    "            'Error extension format: specify correct exentsion, either \\'jpg\\' or \\'tif\\''\n",
    "        )\n",
    "\n",
    "    subdirs_raw = os.listdir(jpg_path)\n",
    "    filenames_raw = []\n",
    "    for subdir in subdirs_raw:\n",
    "        imgs_raw = os.listdir(os.path.join(jpg_path, subdir))\n",
    "        random_sampled = random.sample(imgs_raw, 2000)\n",
    "        if no_imbalanced:\n",
    "            sub_path_imgs = [\n",
    "                os.path.join(subdir, img) for img in random_sampled\n",
    "            ]\n",
    "        else:\n",
    "            sub_path_imgs = [os.path.join(subdir, img) for img in imgs_raw]\n",
    "        filenames_raw.append(sub_path_imgs)\n",
    "    filenames = [\n",
    "        os.path.join(data_path_jpg, f) for sublist in filenames_raw\n",
    "        for f in sublist if f.endswith('.jpg')\n",
    "    ]\n",
    "\n",
    "    pcg_total_files = int(pcg_dataset * len(filenames))\n",
    "    filenames = filenames[:pcg_total_files]\n",
    "\n",
    "    train_val_files_length = int(\n",
    "        0.9 * len(filenames))  # 10% for testing, 90% for val and train\n",
    "    test_files_length = len(filenames) - train_val_files_length\n",
    "\n",
    "    train_files_length = int(\n",
    "        0.7 * train_val_files_length)  # 70% for train, 30% for val\n",
    "    val_files_length = train_val_files_length - train_files_length\n",
    "\n",
    "    params = AttrDict({\n",
    "        'num_channels':\n",
    "        num_channels,\n",
    "        'extension':\n",
    "        extension,\n",
    "        'num_images_train':\n",
    "        train_files_length,\n",
    "        'num_images_val':\n",
    "        val_files_length,\n",
    "        'num_images_test':\n",
    "        test_files_length,\n",
    "        'num_classes':\n",
    "        num_classes,\n",
    "        'parse_bands_verbose':\n",
    "        parse_bands_verbose,\n",
    "        'inspect_raster':\n",
    "        inspect_raster,\n",
    "        'channels':\n",
    "        channels,\n",
    "        'num_epochs':\n",
    "        epochs,\n",
    "        'learning_rate':\n",
    "        learning_rate,\n",
    "        'momentum':\n",
    "        momentum,\n",
    "        'checkpoint':\n",
    "        checkpoint,\n",
    "        'trainable':\n",
    "        trainable,\n",
    "        'pcg_dataset':\n",
    "        pcg_dataset,\n",
    "        'pcg_unfreeze':\n",
    "        pcg_unfreeze,\n",
    "        'preprocess':\n",
    "        preprocess,\n",
    "        'horizontal_flip':\n",
    "        horizontal_flip,\n",
    "        'vertical_flip':\n",
    "        vertical_flip,\n",
    "        'rotation_range':\n",
    "        rotation_range,\n",
    "        'shear_range':\n",
    "        shear_range,\n",
    "        'no_imbalanced':\n",
    "        no_imbalanced,\n",
    "        'batch_size':\n",
    "        batch_size,\n",
    "        'size':\n",
    "        size,\n",
    "        'seed':\n",
    "        seed,\n",
    "        'columns':\n",
    "        columns,\n",
    "        'regularization':\n",
    "        regularization,\n",
    "        'rlronplateau':\n",
    "        rlronplateau,\n",
    "        'num_classes':\n",
    "        num_classes,\n",
    "        'loss_type':\n",
    "        loss_type,\n",
    "        'opt_type':\n",
    "        opt_type,\n",
    "        'loss_obj':\n",
    "        loss_obj(loss_type),\n",
    "        'optimizer_obj':\n",
    "        optimizer(learning_rate, momentum, opt_type),\n",
    "        'raw_jpg_path':\n",
    "        jpg_path,\n",
    "        'raw_tif_path':\n",
    "        tif_path,\n",
    "        'raw_data_path':\n",
    "        raw_data_path,\n",
    "        'data_path_jpg':\n",
    "        data_path_jpg,\n",
    "        'data_path_tif':\n",
    "        data_path_tif,\n",
    "        'weights_path':\n",
    "        weights_path,\n",
    "        'processed_path':\n",
    "        processed_path,\n",
    "        'pickled_tif_path':\n",
    "        pickled_tif_path,\n",
    "        'eurosat_path':\n",
    "        eurosat_path,\n",
    "        'assets_path':\n",
    "        assets_path,\n",
    "        'reprojected_path':\n",
    "        reprojected_path,\n",
    "        'reprojected_path_tif':\n",
    "        reprojected_path_tif,\n",
    "        'reports_maps_path':\n",
    "        reports_maps_path,\n",
    "        'reports_map_eda_path':\n",
    "        reports_map_eda_path,\n",
    "        'reports_map_classifier_path':\n",
    "        reports_map_classifier_path,\n",
    "        'train_data_dir_jpg':\n",
    "        train_data_dir_jpg,\n",
    "        'val_data_dir_jpg':\n",
    "        val_data_dir_jpg,\n",
    "        'test_data_dir_jpg':\n",
    "        test_data_dir_jpg,\n",
    "        'train_data_dir_tif':\n",
    "        train_data_dir_tif,\n",
    "        'val_data_dir_tif':\n",
    "        val_data_dir_tif,\n",
    "        'test_data_dir_tif':\n",
    "        test_data_dir_tif,\n",
    "        'log_folder':\n",
    "        log_folder,\n",
    "        'log_gradient_tape_path':\n",
    "        log_gradient_tape_path,\n",
    "        'log_cm_path':\n",
    "        log_cm_path,\n",
    "        'num_classes':\n",
    "        len(columns)\n",
    "    })\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:04.261039Z",
     "start_time": "2021-05-28T17:24:04.256959Z"
    }
   },
   "outputs": [],
   "source": [
    "def resample(path):\n",
    "    '''Resamples img and returns bands upsampled'''\n",
    "    upscale_factor = 2\n",
    "    # upsample channels to 2x\n",
    "    image = rasterio.open(path)\n",
    "    b01, b02, b03, b04, b05, b06, b07, b08, b08A, b09, b10, b11, b12 = image.read(\n",
    "        out_shape=(image.count, int(image.height * upscale_factor),\n",
    "                   int(image.width * upscale_factor)),\n",
    "        resampling=Resampling.bilinear)\n",
    "\n",
    "    return  # bands that were resampled from 20m to 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:04.803105Z",
     "start_time": "2021-05-28T17:24:04.793927Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_bands(img, params):\n",
    "    '''Parse tif Sentinel-2A images into 13 bands. \n",
    "    Returns: coord_bb,\n",
    "             channels = [b02, b03, b04, b05, b06, b07, b08, b08A, b11, b12] with b05, b06, b07, b08A, b11, b12 upsampled to 10m '''\n",
    "    satdat = rasterio.open(img)\n",
    "    if img.split('/')[-1].endswith('.tif'):\n",
    "        b01, b02, b03, b04, b05, b06, b07, b08, b08A, b09, b10, b11, b12 = satdat.read(\n",
    "        )\n",
    "        channels = [b02, b03, b04, b05, b06, b07, b08, b08A, b11, b12\n",
    "                    ]  # filter out b01, b09, b10 intended for atmosphere study\n",
    "    elif img.split('/')[-1].endswith('.jpg'):\n",
    "        b, g, r = satdat.read()\n",
    "        channels = [b, g, r]\n",
    "\n",
    "    # Get resolution, in map units (meters)\n",
    "    xres = (satdat.bounds.right - satdat.bounds.left) / satdat.width\n",
    "    yres = (satdat.bounds.top - satdat.bounds.bottom) / satdat.height\n",
    "    coord_bb = [\n",
    "        satdat.bounds.left, satdat.bounds.bottom, satdat.bounds.right,\n",
    "        satdat.bounds.top\n",
    "    ]  # coordinate bounding box [left, bottom, right, top]\n",
    "    # geo coordinates [left-long, bottom-lat, right-long, top-lat]\n",
    "    if params.parse_bands_verbose:\n",
    "        print('W resolution (m): {}; H resolution: {}'.format(xres, yres))\n",
    "        print(\"Are the pixels square: {}\".format(xres == yres))\n",
    "        print(satdat.profile)\n",
    "\n",
    "    return coord_bb, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:34:02.956939Z",
     "start_time": "2021-05-28T17:34:02.948236Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_reproj(img, params):\n",
    "    '''Apply affine transformation to array (satdat) and save to file (.tif or .jpg) \n",
    "    path = './data/processed/reprojected/filename; \n",
    "    filename format: rerpoj_{image_name})')'''\n",
    "    target_crs = 'epsg:4326'\n",
    "    satdat = rasterio.open(img)\n",
    "    # calculate a transform and new dimensions using our dataset's current CRS and dimensions\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        satdat.crs, target_crs, satdat.width, satdat.height, *satdat.bounds)\n",
    "    # Copy the metadata\n",
    "    metadata = satdat.meta.copy()\n",
    "    # Change the CRS, transform, and dimensions in metadata to match our desired output dataset\n",
    "    metadata.update({\n",
    "        'crs': target_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    # apply the transform & metadata to perform the reprojection\n",
    "    dst = os.path.join(params.reprojected_path_tif,\n",
    "                       'reproj_' + img.split('/')[-1])\n",
    "\n",
    "    with rasterio.open(dst, 'w', **metadata) as reprojected:\n",
    "        for band in range(1, satdat.count + 1):\n",
    "            reproject(source=rasterio.band(satdat, band),\n",
    "                      destination=rasterio.band(reprojected, band),\n",
    "                      src_transform=satdat.transform,\n",
    "                      src_crs=satdat.crs,\n",
    "                      dst_transform=transform,\n",
    "                      dst_crs=target_crs)\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:06.853272Z",
     "start_time": "2021-05-28T17:24:06.848859Z"
    }
   },
   "outputs": [],
   "source": [
    "def inspect_raster(satdat, img):\n",
    "    '''Inspect raster (after rescaling)'''\n",
    "    fig, ax = plt.subplots(1, 1, dpi=100)\n",
    "    show(satdat.read([4, 3, 2]) * 255 / 65535, ax=ax)\n",
    "    plt.title(img.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:07.278368Z",
     "start_time": "2021-05-28T17:24:07.273954Z"
    }
   },
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    new_dir = path\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:07.771885Z",
     "start_time": "2021-05-28T17:24:07.767011Z"
    }
   },
   "outputs": [],
   "source": [
    "def percentage(count_tags):\n",
    "    _sum = sum(count_tags.values())\n",
    "    return [(el / _sum) * 100 for el in count_tags.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:08.198586Z",
     "start_time": "2021-05-28T17:24:08.193261Z"
    }
   },
   "outputs": [],
   "source": [
    "def cmap_rescale(elements):\n",
    "    result = []\n",
    "    if isinstance(elements, dict):\n",
    "        _max = max(elements.values())\n",
    "        _min = min(elements.values())\n",
    "        result = [(el - _min) / (_max - _min) for el in elements.values()]\n",
    "    if isinstance(elements, list):\n",
    "        _max = np.max(elements.values())\n",
    "        _min = np.min(elements.values())\n",
    "        result = [(el - _min) / (_max - _min) for el in elements.values()]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:08.636260Z",
     "start_time": "2021-05-28T17:24:08.630656Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_hex(rgba_color):\n",
    "    red = str(hex(int(rgba_color[0] * 255)))[2:].capitalize()\n",
    "    green = str(hex(int(rgba_color[1] * 255)))[2:].capitalize()\n",
    "    blue = str(hex(int(rgba_color[2] * 255)))[2:].capitalize()\n",
    "\n",
    "    if blue == '0':\n",
    "        blue = '00'\n",
    "    if red == '0':\n",
    "        red = '00'\n",
    "    if green == '0':\n",
    "        green = '00'\n",
    "\n",
    "    return '#' + red + green + blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:09.098932Z",
     "start_time": "2021-05-28T17:24:09.091616Z"
    }
   },
   "outputs": [],
   "source": [
    "def dirs2df(img_path):\n",
    "    '''From img directory to dataframe. \n",
    "    input path images folder\n",
    "    return df\n",
    "    ------------------------------------\n",
    "    img directory tree: |images\n",
    "                        |      --> labels\n",
    "                        |               --> .tif or .jpg'''\n",
    "    dirs_path = []\n",
    "    dirs = []\n",
    "    dirs = os.listdir(img_path)\n",
    "    dirs_path = [os.path.join(img_path, _dir) for _dir in dirs]\n",
    "\n",
    "    imgdict = {}\n",
    "    img_names = []\n",
    "    img_paths = []\n",
    "    for _dir in dirs_path:\n",
    "        if _dir.split('/')[-1] != '.DS_Store':\n",
    "            nameslist = os.listdir(_dir)\n",
    "        for el in nameslist:\n",
    "            if el.endswith('.jpg') | el.endswith('.tif'):\n",
    "                img_names.append(el)\n",
    "                img_paths.append(os.path.join(_dir, el))\n",
    "        imgdict['image_name'] = img_names\n",
    "    df = pd.DataFrame.from_dict(imgdict)\n",
    "    df['label'] = df['image_name'].apply(lambda x: x.split('_')[0])\n",
    "    return df, img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:09.527777Z",
     "start_time": "2021-05-28T17:24:09.507993Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_filenames(df, params):\n",
    "    # pcg_dataset = percentage of total files to use: i.e. 30% of 40479 samples = 12143 samples\n",
    "    # empty data dirs\n",
    "    if df['image_name'].iloc[0].endswith('.jpg'):\n",
    "        print('Format: jpg')\n",
    "        train_data_dir = params.train_data_dir_jpg\n",
    "        val_data_dir = params.val_data_dir_jpg\n",
    "        test_data_dir = params.test_data_dir_jpg\n",
    "        raw_data_dir = params.raw_jpg_path\n",
    "        endswith = '.jpg'\n",
    "\n",
    "    if df['image_name'].iloc[0].endswith('.tif'):\n",
    "        print('Format: tif')\n",
    "        train_data_dir = params.train_data_dir_tif\n",
    "        val_data_dir = params.val_data_dir_tif\n",
    "        test_data_dir = params.test_data_dir_tif\n",
    "        raw_data_dir = params.raw_tif_path\n",
    "        endswith = '.tif'\n",
    "\n",
    "    data_dirs = [train_data_dir, val_data_dir, test_data_dir]\n",
    "    for data_dir in data_dirs:\n",
    "        for file in os.listdir(data_dir):\n",
    "            os.remove(os.path.join(data_dir, file))\n",
    "    # create lists of filenames for train, val, test sets\n",
    "    # copy lists of images from raw folder to train, val, test folders using lists of filenames\n",
    "\n",
    "    pcg_total_files = int(params.pcg_dataset * len(df))\n",
    "\n",
    "    subdirs_raw = os.listdir(raw_data_dir)\n",
    "    filenames_raw = []\n",
    "    for subdir in subdirs_raw:\n",
    "        imgs_raw = os.listdir(os.path.join(raw_data_dir, subdir))\n",
    "        random_sampled = random.sample(imgs_raw, 2000)\n",
    "        if params.no_imbalanced:\n",
    "            sub_path_imgs = [\n",
    "                os.path.join(subdir, img) for img in random_sampled\n",
    "            ]\n",
    "        else:\n",
    "            sub_path_imgs = [os.path.join(subdir, img) for img in imgs_raw]\n",
    "        filenames_raw.append(sub_path_imgs)\n",
    "    filenames = [\n",
    "        os.path.join(raw_data_dir, f) for sublist in filenames_raw\n",
    "        for f in sublist if f.endswith(endswith)\n",
    "    ]\n",
    "\n",
    "    seed = random.seed(123)\n",
    "    filenames.sort()\n",
    "    random.shuffle(filenames)\n",
    "\n",
    "    filenames = filenames[:pcg_total_files]\n",
    "\n",
    "    split_train_test = int(\n",
    "        0.9 * len(filenames))  # 10% for testing, 90% for val and train\n",
    "    train_filenames_raw = filenames[:split_train_test]\n",
    "    test_filenames_raw = filenames[split_train_test:]\n",
    "\n",
    "    split_train_val = int(\n",
    "        0.7 * len(train_filenames_raw))  # 70% for train, 30% for val\n",
    "    val_filenames_raw = train_filenames_raw[split_train_val:]\n",
    "    train_filenames_raw = train_filenames_raw[:split_train_val]\n",
    "\n",
    "    train_val_test = [\n",
    "        train_filenames_raw, val_filenames_raw, test_filenames_raw\n",
    "    ]\n",
    "    dest_dirs = [train_data_dir, val_data_dir, test_data_dir]\n",
    "\n",
    "    for filename_dir, dest_dir in tqdm(zip(train_val_test, dest_dirs)):\n",
    "        if len(os.listdir(dest_dir)) != len(\n",
    "                filename_dir):  #check if directory is empty\n",
    "            for filename in filename_dir:\n",
    "                shutil.copy(filename, dest_dir)\n",
    "\n",
    "    # get lists of filenames with new path (i.e. '.data/jpg/train/img_name.jpg')\n",
    "    train_filenames = []\n",
    "    val_filenames = []\n",
    "    test_filenames = []\n",
    "\n",
    "    for filename_dir, dest_dir in tqdm(zip(train_val_test, dest_dirs)):\n",
    "        for filename in filename_dir:\n",
    "            if dest_dir == train_data_dir:\n",
    "                train_filenames.append(\n",
    "                    os.path.join(dest_dir,\n",
    "                                 filename.split('/')[-1]))\n",
    "            elif dest_dir == val_data_dir:\n",
    "                val_filenames.append(\n",
    "                    os.path.join(dest_dir,\n",
    "                                 filename.split('/')[-1]))\n",
    "            elif dest_dir == test_data_dir:\n",
    "                test_filenames.append(\n",
    "                    os.path.join(dest_dir,\n",
    "                                 filename.split('/')[-1]))\n",
    "\n",
    "    train_val_test = [train_filenames, val_filenames, test_filenames]\n",
    "\n",
    "    #get names of images for each set\n",
    "    train_filenames_img = [el.split('/')[-1] for el in train_filenames_raw]\n",
    "    val_filenames_img = [el.split('/')[-1] for el in val_filenames_raw]\n",
    "    test_filenames_img = [el.split('/')[-1] for el in test_filenames_raw]\n",
    "\n",
    "    data_filenames_img = [\n",
    "        train_filenames_img, val_filenames_img, test_filenames_img\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        'Total number of samples (train + val + test) (%d %% of original dataset) : %d'\n",
    "        % (params.pcg_dataset * 100, len(filenames)))\n",
    "    print('Training set - number of samples: %d' % len(train_filenames_raw))\n",
    "    print('Validation set - number of samples: %d' % len(val_filenames_raw))\n",
    "    print('Test set - number of samples: %d' % len(test_filenames_raw))\n",
    "\n",
    "    print('Training set - number of samples in .data/train: %d' %\n",
    "          len(os.listdir(train_data_dir)))\n",
    "    print('Validation set - number of samples .data/val: %d' %\n",
    "          len(os.listdir(val_data_dir)))\n",
    "    print('Test set - number of samples .data/test: %d' %\n",
    "          len(os.listdir(test_data_dir)))\n",
    "\n",
    "    return train_val_test, data_filenames_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:14.430062Z",
     "start_time": "2021-05-28T17:24:14.425967Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_obj(loss_type):\n",
    "    if loss_type == 'categorical_crossentropy':\n",
    "        loss_obj = tf.keras.losses.CategoricalCrossentropy()\n",
    "    return loss_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:14.783735Z",
     "start_time": "2021-05-28T17:24:14.779083Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimizer(learning_rate, momentum, opt_type):\n",
    "    if opt_type == 'SGD_momentum':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                      momentum=momentum)\n",
    "    if opt_type == 'Adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                       decay=0.0001)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:14.917304Z",
     "start_time": "2021-05-28T17:24:14.896553Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_using_keras(folders, df, data_filenames_img, params):\n",
    "    image_generator = {}\n",
    "    data_generator = {}\n",
    "\n",
    "    for _dir, _filenames in zip(folders, data_filenames_img):\n",
    "        end = _dir.split('/')[-1]\n",
    "        if params.preprocess:\n",
    "\n",
    "            if end == 'train':\n",
    "                image_generator['train'] = ImageDataGenerator(\n",
    "                    horizontal_flip=params.horizontal_flip,\n",
    "                    vertical_flip=params.vertical_flip,\n",
    "                    rotation_range=params.rotation_range,\n",
    "                    shear_range=params.shear_range)\n",
    "\n",
    "                data_generator['train'] = image_generator[\n",
    "                    'train'].flow_from_dataframe(\n",
    "                        dataframe=df[df['image_name'].isin(_filenames)],\n",
    "                        x_col='image_name',\n",
    "                        y_col=params.columns,\n",
    "                        batch_size=params.batch_size,\n",
    "                        directory=_dir,\n",
    "                        seed=params.seed,\n",
    "                        shuffle=True,\n",
    "                        target_size=(64, 64),\n",
    "                        class_mode='raw',\n",
    "                        color_mode='rgb')\n",
    "\n",
    "            if end == 'val':\n",
    "                image_generator['val'] = ImageDataGenerator()\n",
    "                data_generator['val'] = image_generator[\n",
    "                    'val'].flow_from_dataframe(\n",
    "                        dataframe=df[df['image_name'].isin(_filenames)],\n",
    "                        x_col='image_name',\n",
    "                        y_col=params.columns,\n",
    "                        batch_size=params.batch_size,\n",
    "                        directory=_dir,\n",
    "                        seed=params.seed,\n",
    "                        shuffle=False,\n",
    "                        target_size=(64, 64),\n",
    "                        class_mode='raw',\n",
    "                        color_mode='rgb')\n",
    "\n",
    "            if end == 'test':\n",
    "                image_generator['test'] = ImageDataGenerator()\n",
    "                data_generator['test'] = image_generator[\n",
    "                    'test'].flow_from_dataframe(\n",
    "                        dataframe=df[df['image_name'].isin(_filenames)],\n",
    "                        x_col='image_name',\n",
    "                        y_col=params.columns,\n",
    "                        batch_size=len(df[df['image_name'].isin(_filenames)]),\n",
    "                        directory=_dir,\n",
    "                        seed=params.seed,\n",
    "                        shuffle=False,\n",
    "                        target_size=(64, 64),\n",
    "                        class_mode='raw',\n",
    "                        color_mode='rgb')\n",
    "\n",
    "        else:\n",
    "            if end == 'train':\n",
    "                image_generator['train'] = ImageDataGenerator(\n",
    "                    horizontal_flip=params.horizontal_flip,\n",
    "                    vertical_flip=params.vertical_flip,\n",
    "                    rotation_range=params.rotation_range,\n",
    "                    shear_range=params.shear_range,\n",
    "                    rescale=1. / 255)\n",
    "\n",
    "                data_generator['train'] = image_generator[\n",
    "                    'train'].flow_from_dataframe(\n",
    "                        dataframe=df[df['image_name'].isin(_filenames)],\n",
    "                        x_col='image_name',\n",
    "                        y_col=params.columns,\n",
    "                        batch_size=params.batch_size,\n",
    "                        directory=_dir,\n",
    "                        seed=params.seed,\n",
    "                        shuffle=True,\n",
    "                        target_size=(64, 64),\n",
    "                        class_mode='raw',\n",
    "                        color_mode='rgb')\n",
    "\n",
    "            if end == 'val':\n",
    "                image_generator['val'] = ImageDataGenerator(rescale=1. / 255)\n",
    "                data_generator['val'] = image_generator[\n",
    "                    'val'].flow_from_dataframe(\n",
    "                        dataframe=df[df['image_name'].isin(_filenames)],\n",
    "                        x_col='image_name',\n",
    "                        y_col=params.columns,\n",
    "                        batch_size=params.batch_size,\n",
    "                        directory=_dir,\n",
    "                        seed=params.seed,\n",
    "                        shuffle=False,\n",
    "                        target_size=(64, 64),\n",
    "                        class_mode='raw',\n",
    "                        color_mode='rgb')\n",
    "\n",
    "            if end == 'test':\n",
    "                image_generator['test'] = ImageDataGenerator(rescale=1. / 255)\n",
    "                data_generator['test'] = image_generator[\n",
    "                    'test'].flow_from_dataframe(\n",
    "                        dataframe=df[df['image_name'].isin(_filenames)],\n",
    "                        x_col='image_name',\n",
    "                        y_col=params.columns,\n",
    "                        batch_size=len(df[df['image_name'].isin(_filenames)]),\n",
    "                        directory=_dir,\n",
    "                        seed=params.seed,\n",
    "                        shuffle=False,\n",
    "                        target_size=(64, 64),\n",
    "                        class_mode='raw',\n",
    "                        color_mode='rgb')\n",
    "\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:15.773438Z",
     "start_time": "2021-05-28T17:24:15.769202Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_band(band):\n",
    "    # min-max norm\n",
    "    MinMax = MinMaxScaler()\n",
    "    band_norm = MinMax.fit_transform(band)\n",
    "    return band_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:16.412224Z",
     "start_time": "2021-05-28T17:24:16.392902Z"
    }
   },
   "outputs": [],
   "source": [
    "def tif2sets(train_val_test_tif, dataset_tif, params):\n",
    "    '''This function parses tiff images from images path, returns train, val, test set with upsampled bands'''\n",
    "    # initialize\n",
    "    if params.channels == 'all':\n",
    "        X_train = np.zeros([len(train_val_test_tif[0]), 64, 64, 10],\n",
    "                           dtype=\"float32\")\n",
    "        X_val = np.zeros([len(train_val_test_tif[1]), 64, 64, 10],\n",
    "                         dtype=\"float32\")\n",
    "        X_test = np.zeros([len(train_val_test_tif[2]), 64, 64, 10],\n",
    "                          dtype=\"float32\")\n",
    "        y_train = np.zeros([len(train_val_test_tif[0]), 10])\n",
    "        y_val = np.zeros([len(train_val_test_tif[1]), 10])\n",
    "        y_test = np.zeros([len(train_val_test_tif[2]), 10])\n",
    "\n",
    "    else:\n",
    "        X_train = np.zeros(\n",
    "            [len(train_val_test_tif[0]), 64, 64,\n",
    "             len(params.channels)],\n",
    "            dtype=\"float32\")\n",
    "        X_val = np.zeros(\n",
    "            [len(train_val_test_tif[1]), 64, 64,\n",
    "             len(params.channels)],\n",
    "            dtype=\"float32\")\n",
    "        X_test = np.zeros(\n",
    "            [len(train_val_test_tif[2]), 64, 64,\n",
    "             len(params.channels)],\n",
    "            dtype=\"float32\")\n",
    "        y_train = np.zeros([len(train_val_test_tif[0]), len(params.channels)])\n",
    "        y_val = np.zeros([len(train_val_test_tif[1]), len(params.channels)])\n",
    "        y_test = np.zeros([len(train_val_test_tif[2]), len(params.channels)])\n",
    "\n",
    "    sets = [(X_train, y_train), (X_val, y_val), (X_test, y_test)]\n",
    "\n",
    "    for folder, _set in zip(train_val_test_tif, sets):\n",
    "        X_set, y_set = _set\n",
    "        for i in range(len(_set[0])):\n",
    "            X_set[i, :, :, :] = dataset_tif[folder[i].split('/')\n",
    "                                            [-1]]['X_array']\n",
    "            y_set[i, :] = dataset_tif[folder[i].split('/')[-1]]['y_array']\n",
    "\n",
    "    print('Number of samples in train set: {}'.format(len(sets[0][0])))\n",
    "    print('Number of labels in train set: {}'.format(len(sets[0][-1])))\n",
    "    print('\\nNumber of samples in val set: {}'.format(len(sets[1][0])))\n",
    "    print('Number of labels in val set: {}'.format(len(sets[1][-1])))\n",
    "    print('\\nNumber of samples in test set: {}'.format(len(sets[-1][0])))\n",
    "    print('Number of labels in test set: {}'.format(len(sets[-1][-1])))\n",
    "    print('\\nTotal number of samples: {}'.format(\n",
    "        len(sets[0][0]) + len(sets[1][0]) + len(sets[2][0])))\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:17.446489Z",
     "start_time": "2021-05-28T17:24:17.436573Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_using_keras_tif(train_val_test_tif, dataset_tif, params):\n",
    "    data_generators = {}\n",
    "\n",
    "    train_val_test_sets = tif2sets(train_val_test_tif, dataset_tif, params)\n",
    "    X_train, y_train = train_val_test_sets[0]\n",
    "    X_val, y_val = train_val_test_sets[1]\n",
    "    X_test, y_test = train_val_test_sets[2]\n",
    "\n",
    "    image_generator = ImageDataGenerator(\n",
    "        horizontal_flip=params.horizontal_flip,\n",
    "        vertical_flip=params.vertical_flip,\n",
    "        rotation_range=params.rotation_range,\n",
    "        shear_range=params.shear_range)\n",
    "\n",
    "    data_generators['train'] = image_generator.flow(\n",
    "        X_train, y_train, batch_size=params.batch_size, seed=params.seed)\n",
    "\n",
    "    data_generators['val'] = image_generator.flow(X_val,\n",
    "                                                  y_val,\n",
    "                                                  batch_size=params.batch_size,\n",
    "                                                  seed=params.seed)\n",
    "\n",
    "    data_generators['test'] = image_generator.flow(\n",
    "        X_test, y_test, batch_size=params.batch_size, seed=params.seed)\n",
    "\n",
    "    return data_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:17.832472Z",
     "start_time": "2021-05-28T17:24:17.821522Z"
    }
   },
   "outputs": [],
   "source": [
    "def spectral_module(x, spectral_id, squeeze=16, expand_1x1=96, expand_3x3=32):\n",
    "    sq1x1 = \"squeeze1x1\"\n",
    "    exp1x1 = \"expand1x1\"\n",
    "    exp3x3 = \"expand3x3\"\n",
    "    relu = \"relu_\"\n",
    "    s_id = 'spectral' + str(spectral_id) + '/'\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "\n",
    "    x = Conv2D(squeeze, (1, 1),\n",
    "               padding='same',\n",
    "               name=s_id + sq1x1,\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               activation='relu')(x)\n",
    "\n",
    "    left = Conv2D(expand_1x1, (1, 1),\n",
    "                  padding='same',\n",
    "                  name=s_id + exp1x1,\n",
    "                  kernel_initializer='glorot_uniform')(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Conv2D(expand_3x3, (3, 3),\n",
    "                   padding='same',\n",
    "                   name=s_id + exp3x3,\n",
    "                   kernel_initializer='glorot_uniform')(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:18.723158Z",
     "start_time": "2021-05-28T17:24:18.710083Z"
    }
   },
   "outputs": [],
   "source": [
    "def SpectralNet(params, input_shape=(64, 64, 10), classes=10):\n",
    "    \"\"\"Implementation of SpectralNet architecture - Jacob J. Senecal, John W. Sheppard, Joseph A. Shaw\n",
    "                                                  - Gianforte School of Computing and Dept. Elec & Computer Engineering\n",
    "                                                  - Montana State University, Bozeman, USA\n",
    "                                \n",
    "    paper: https://www.cs.montana.edu/sheppard/pubs/ijcnn-2019c.pdf\n",
    "    \n",
    "    modifing SqueezeNet implementation in Keras: https://github.com/rcmalli/keras-squeezenet\n",
    "    \"\"\"\n",
    "    if params.extension == 'jpg':\n",
    "        input_shape = (64, 64, 3)\n",
    "    elif params.extension == 'tif':\n",
    "        input_shape = (64, 64, 10)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = Conv2D(96, (2, 2),\n",
    "               strides=(2, 2),\n",
    "               padding='same',\n",
    "               name='conv1',\n",
    "               activation='relu',\n",
    "               kernel_initializer='glorot_uniform')(inputs)\n",
    "    x = spectral_module(x,\n",
    "                        spectral_id=2,\n",
    "                        squeeze=16,\n",
    "                        expand_1x1=96,\n",
    "                        expand_3x3=32)\n",
    "    x = spectral_module(x,\n",
    "                        spectral_id=3,\n",
    "                        squeeze=16,\n",
    "                        expand_1x1=96,\n",
    "                        expand_3x3=32)\n",
    "    x = spectral_module(x,\n",
    "                        spectral_id=4,\n",
    "                        squeeze=32,\n",
    "                        expand_1x1=192,\n",
    "                        expand_3x3=64)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool4')(x)\n",
    "\n",
    "    x = spectral_module(x,\n",
    "                        spectral_id=5,\n",
    "                        squeeze=32,\n",
    "                        expand_1x1=192,\n",
    "                        expand_3x3=64)\n",
    "    x = spectral_module(x,\n",
    "                        spectral_id=6,\n",
    "                        squeeze=48,\n",
    "                        expand_1x1=288,\n",
    "                        expand_3x3=96)\n",
    "    x = spectral_module(x,\n",
    "                        spectral_id=7,\n",
    "                        squeeze=48,\n",
    "                        expand_1x1=288,\n",
    "                        expand_3x3=96)\n",
    "    x = spectral_module(x,\n",
    "                        spectral_id=8,\n",
    "                        squeeze=64,\n",
    "                        expand_1x1=385,\n",
    "                        expand_3x3=128)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool8')(x)\n",
    "\n",
    "    x = spectral_module(x,\n",
    "                        spectral_id=9,\n",
    "                        squeeze=64,\n",
    "                        expand_1x1=385,\n",
    "                        expand_3x3=128)\n",
    "\n",
    "    x = Conv2D(classes, (1, 1),\n",
    "               padding='same',\n",
    "               name='conv10',\n",
    "               activation='relu',\n",
    "               kernel_initializer='glorot_uniform')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    softmax = Activation(\"softmax\", name='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, softmax)\n",
    "    model.compile(loss=params.loss_obj,\n",
    "                  optimizer=params.optimizer_obj,\n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:19.534602Z",
     "start_time": "2021-05-28T17:24:19.497109Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(version, params):\n",
    "\n",
    "    if version == 'v1.0':\n",
    "        # Baseline\n",
    "        inputs = Input(shape=(params.size, params.size, params.num_channels))\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "\n",
    "        outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        model.compile(loss=params.loss_obj,\n",
    "                      optimizer=params.optimizer_obj,\n",
    "                      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    if version == 'v1.1':\n",
    "        # v1.0 with 128 units in FC layer w.r.t 64\n",
    "        inputs = Input(shape=(params.size, params.size, params.num_channels))\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   kernel_initializer='he_uniform',\n",
    "                   padding='same')(x)\n",
    "        x = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   kernel_initializer='he_uniform',\n",
    "                   padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "\n",
    "        outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        model.compile(loss=params.loss_obj,\n",
    "                      optimizer=params.optimizer_obj,\n",
    "                      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    if version == 'v1.2':\n",
    "        # v1.3 with dropout layers after each block\n",
    "        inputs = Input(shape=(params.size, params.size, params.num_channels))\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "\n",
    "        outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        model.compile(loss=params.loss_obj,\n",
    "                      optimizer=params.optimizer_obj,\n",
    "                      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    if version == 'v1.3':\n",
    "        inputs = Input(shape=(params.size, params.size, params.num_channels))\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "\n",
    "        outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        model.compile(loss=params.loss_obj,\n",
    "                      optimizer=params.optimizer_obj,\n",
    "                      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    if version == 'v1.4':\n",
    "        inputs = Input(shape=(params.size, params.size, params.num_channels))\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "        outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        model.compile(loss=params.loss_obj,\n",
    "                      optimizer=params.optimizer_obj,\n",
    "                      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:20.206020Z",
     "start_time": "2021-05-28T17:24:20.172725Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_resnet(params):\n",
    "    if params.trainable == True:\n",
    "        print('\\n Unfreezing ResNet {}% top layers'.format(\n",
    "            params.pcg_unfreeze * 100))\n",
    "        layers_to_freeze = 175 - int(\n",
    "            175 * params.pcg_unfreeze\n",
    "        )  #resnet has 175 layers; this is the number of layers to freeze\n",
    "        base_model = tf.keras.applications.ResNet50(\n",
    "            input_shape=(params.size, params.size, params.num_channels),\n",
    "            include_top=False,\n",
    "            weights='imagenet')\n",
    "\n",
    "        for layer in base_model.layers[:layers_to_freeze]:\n",
    "            layer.trainable = False\n",
    "        for layer in base_model.layers[layers_to_freeze:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        if params.regularization:\n",
    "            base_model = add_regularization(\n",
    "                base_model, regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "            print('L2 regularization added')\n",
    "\n",
    "        if params.preprocess:\n",
    "            inputs = tf.keras.Input(shape=(params.size, params.size,\n",
    "                                           params.num_channels))\n",
    "            x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "            x = base_model(x, training=False)\n",
    "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "            model.compile(loss=params.loss_obj,\n",
    "                          optimizer=params.optimizer_obj,\n",
    "                          metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        else:\n",
    "            inputs = tf.keras.Input(shape=(params.size, params.size,\n",
    "                                           params.num_channels))\n",
    "            x = base_model(inputs, training=False)\n",
    "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "            model.compile(loss=params.loss_obj,\n",
    "                          optimizer=params.optimizer_obj,\n",
    "                          metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    elif (params.trainable == 'Full'):\n",
    "\n",
    "        print('\\n Using Resnet - Full training'.format(params.pcg_unfreeze))\n",
    "        base_model = tf.keras.applications.ResNet50(\n",
    "            input_shape=(params.size, params.size, params.num_channels),\n",
    "            include_top=False,\n",
    "            weights='imagenet')\n",
    "\n",
    "        if params.preprocess:\n",
    "            print('\\n Using Keras preprocess_input')\n",
    "            base_model.trainable = True\n",
    "            if params.regularization:\n",
    "                base_model = add_regularization(\n",
    "                    base_model, regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "                print('L2 regularization added')\n",
    "            inputs = tf.keras.Input(shape=(params.size, params.size,\n",
    "                                           params.num_channels))\n",
    "            x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "            x = base_model(x, training=False)\n",
    "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "            model.compile(loss=params.loss_obj,\n",
    "                          optimizer=params.optimizer_obj,\n",
    "                          metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        else:\n",
    "            base_model.trainable = True\n",
    "            if params.regularization:\n",
    "                base_model = add_regularization(\n",
    "                    base_model, regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "                print('L2 regularization added')\n",
    "            inputs = tf.keras.Input(shape=(params.size, params.size,\n",
    "                                           params.num_channels))\n",
    "            x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "            x = base_model(x, training=False)\n",
    "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "            model.compile(loss=params.loss_obj,\n",
    "                          optimizer=params.optimizer_obj,\n",
    "                          metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    else:\n",
    "        print('\\n Using Resnet as feature extractor'.format(\n",
    "            params.pcg_unfreeze))\n",
    "        base_model = tf.keras.applications.ResNet50(\n",
    "            input_shape=(params.size, params.size, params.num_channels),\n",
    "            include_top=False,\n",
    "            weights='imagenet')\n",
    "\n",
    "        if params.preprocess:\n",
    "            base_model.trainable = False\n",
    "            if params.regularization:\n",
    "                print('L2 regularization added')\n",
    "                base_model = add_regularization(\n",
    "                    base_model, regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "            inputs = tf.keras.Input(shape=(params.size, params.size,\n",
    "                                           params.num_channels))\n",
    "            x = tf.keras.applications.mobilenet.preprocess_input(inputs)\n",
    "            x = base_model(x, training=False)\n",
    "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "            model.compile(loss=params.loss_obj,\n",
    "                          optimizer=params.optimizer_obj,\n",
    "                          metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        else:\n",
    "            base_model.trainable = False\n",
    "            inputs = tf.keras.Input(shape=(params.size, params.size,\n",
    "                                           params.num_channels))\n",
    "            x = base_model(inputs, training=False)\n",
    "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            outputs = Dense(params.num_classes, activation='softmax')(x)\n",
    "            model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "            model.compile(loss=params.loss_obj,\n",
    "                          optimizer=params.optimizer_obj,\n",
    "                          metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:21.179635Z",
     "start_time": "2021-05-28T17:24:21.167718Z"
    }
   },
   "outputs": [],
   "source": [
    "# credits to Thalles Silva: https://gist.github.com/sthalles\n",
    "def add_regularization(model, regularizer=tf.keras.regularizers.l2(0.0001)):\n",
    "\n",
    "    if not isinstance(regularizer, tf.keras.regularizers.Regularizer):\n",
    "        print(\n",
    "            \"Regularizer must be a subclass of tf.keras.regularizers.Regularizer\"\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    for layer in model.layers:\n",
    "        for attr in ['kernel_regularizer']:\n",
    "            if hasattr(layer, attr):\n",
    "                setattr(layer, attr, regularizer)\n",
    "\n",
    "    # Save the weights before reloading the model.\n",
    "    config_json = model.to_json()\n",
    "    tmp_weights_path = os.path.join(tempfile.gettempdir(),\n",
    "                                    'tmp_weights_resnet.h5')\n",
    "    model.save_weights(tmp_weights_path)\n",
    "\n",
    "    model = tf.keras.models.model_from_json(config_json)\n",
    "    # Reload the model weights\n",
    "    model.load_weights(tmp_weights_path, by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T03:25:15.491859Z",
     "start_time": "2021-05-29T03:25:15.472773Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_models_generator(versions,\n",
    "                         data_generator,\n",
    "                         test_dataset,\n",
    "                         test_labels,\n",
    "                         train_params,\n",
    "                         experiment=''):\n",
    "    v_outputs = {}\n",
    "    log_folder = train_params.log_folder\n",
    "    log_cm_path = train_params.log_cm_path\n",
    "    for i, version in enumerate(versions):\n",
    "        v = []\n",
    "        v_history = []\n",
    "        v_loss = []\n",
    "        v_grid = []\n",
    "        v_dict = {}\n",
    "\n",
    "        version_folder = os.path.join(log_folder, version + experiment)\n",
    "        mkdir(log_cm_path)\n",
    "        v, v_history, v_loss, v_grid = run_baseline_model_generator(\n",
    "            version, data_generator, test_dataset, test_labels, train_params,\n",
    "            version_folder)\n",
    "        shutil.copytree(log_cm_path, os.path.join(version_folder, 'cm'))\n",
    "        shutil.rmtree(log_cm_path)\n",
    "\n",
    "        v_meta = {\n",
    "            'channels': train_params.channels,\n",
    "            'image_size': train_params.size,\n",
    "            'num_images_train': train_params.num_images_train,\n",
    "            'num_images_val': train_params.num_images_val,\n",
    "            'num_images_test': train_params.num_images_test,\n",
    "            'channels': train_params.num_channels,\n",
    "            'epochs': train_params.num_epochs,\n",
    "            'batch_size': train_params.batch_size,\n",
    "            'loss_type': train_params.loss_type,\n",
    "            'opt_type': train_params.opt_type,\n",
    "            'learning_rate': train_params.learning_rate,\n",
    "            'momentum': train_params.momentum,\n",
    "            'regularization': train_params.regularization,\n",
    "            'horizontal_flip': train_params.horizontal_flip,\n",
    "            'vertical_flip': train_params.vertical_flip,\n",
    "            'rotation_range': train_params.rotation_range,\n",
    "            'shear_range': train_params.shear_range\n",
    "        }\n",
    "\n",
    "        v_dict['meta'] = v_meta\n",
    "        v_dict['model'] = v\n",
    "        v_dict['history'] = v_history\n",
    "        v_dict['loss'] = v_loss\n",
    "        v_dict['grid'] = v_grid\n",
    "\n",
    "        v_outputs[version] = v_dict\n",
    "\n",
    "    return v_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:22.890953Z",
     "start_time": "2021-05-28T17:24:22.872276Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_baseline_model_generator(version, data_generator, test_dataset,\n",
    "                                 test_labels, train_params, version_folder):\n",
    "    if version.startswith('ResNet'):\n",
    "        model = create_resnet(train_params)\n",
    "        print('Version: Resnet model - {}'.format(\n",
    "            version_folder.split('/')[-1]))\n",
    "\n",
    "    elif version.startswith('SpectralNet'):\n",
    "        model = SpectralNet(train_params)\n",
    "        print('Version: SpectralNet model - {}'.format(\n",
    "            version_folder.split('/')[-1]))\n",
    "    else:\n",
    "        model = create_model(version, train_params)\n",
    "        print('Version: {}'.format(version_folder.split('/')[-1]))\n",
    "\n",
    "    # History\n",
    "\n",
    "    if train_params.rlronplateau:\n",
    "        print('RLRonPlateau: active\\n')\n",
    "        cm_callback = ConfusionMatrixCallback(test_dataset, test_labels,\n",
    "                                              train_params)\n",
    "        ReduceLRonPLateau_callback = ReduceLROnPlateau(monitor='loss',\n",
    "                                                       factor=0.1,\n",
    "                                                       patience=3,\n",
    "                                                       mode='min',\n",
    "                                                       min_lr=0.000001)\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=os.path.join(\n",
    "                version_folder,\n",
    "                datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "            histogram_freq=1)\n",
    "\n",
    "        history = model.fit_generator(\n",
    "            data_generator['train'],\n",
    "            steps_per_epoch=train_params.num_images_train //\n",
    "            train_params.batch_size,\n",
    "            epochs=train_params.num_epochs,\n",
    "            validation_data=data_generator['val'],\n",
    "            validation_steps=train_params.num_images_val //\n",
    "            train_params.batch_size,\n",
    "            callbacks=[\n",
    "                tensorboard_callback, cm_callback, ReduceLRonPLateau_callback\n",
    "            ])\n",
    "\n",
    "    else:\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=os.path.join(\n",
    "                version_folder,\n",
    "                datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "            histogram_freq=1)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm_callback = ConfusionMatrixCallback(test_dataset, test_labels,\n",
    "                                              train_params)\n",
    "        history = model.fit_generator(\n",
    "            data_generator['train'],\n",
    "            steps_per_epoch=train_params.num_images_train //\n",
    "            train_params.batch_size,\n",
    "            epochs=train_params.num_epochs,\n",
    "            validation_data=data_generator['val'],\n",
    "            validation_steps=train_params.num_images_val //\n",
    "            train_params.batch_size,\n",
    "            callbacks=[tensorboard_callback, cm_callback])\n",
    "\n",
    "    loss, val_loss, categorical_accuracy, val_categorical_accuracy = learning_curves(\n",
    "        history, version)\n",
    "    grid = perf_grid(test_dataset,\n",
    "                     test_labels,\n",
    "                     train_params.columns,\n",
    "                     model,\n",
    "                     n_thresh=100)\n",
    "\n",
    "    return model, history, loss, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T03:26:34.385832Z",
     "start_time": "2021-05-29T03:26:34.381024Z"
    }
   },
   "outputs": [],
   "source": [
    "def results_to_file(versions, experiment):\n",
    "    # save\n",
    "    assets_path = './reports/assets/'\n",
    "    saved_models_dir = './reports/saved_models'\n",
    "\n",
    "    save_path = os.path.join(assets_path,\n",
    "                             list(versions.keys())[0] + experiment)\n",
    "    save_meta_csv_path = os.path.join(\n",
    "        save_path,\n",
    "        list(versions.keys())[0] + experiment + '_meta_.csv')\n",
    "    save_grid_csv_path = os.path.join(\n",
    "        save_path,\n",
    "        list(versions.keys())[0] + experiment + '_grid_.csv')\n",
    "    mkdir(save_path)\n",
    "\n",
    "    df_meta = pd.DataFrame(versions['ResNet']['meta']).iloc[0]\n",
    "    df_grid = pd.DataFrame(versions['ResNet']['grid'])\n",
    "\n",
    "    # save meta and grid to csv\n",
    "    pd.DataFrame.to_csv(df_meta, save_meta_csv_path, index=False)\n",
    "    pd.DataFrame.to_csv(df_grid, save_grid_csv_path, index=False)\n",
    "\n",
    "    # save model\n",
    "    versions['ResNet']['model'].save(\n",
    "        os.path.join(saved_models_dir,\n",
    "                     list(versions.keys())[0] + experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:24.452026Z",
     "start_time": "2021-05-28T17:24:24.442035Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrixCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_test, y_test, params):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.params = params\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_params = params('jpg', 1)\n",
    "        log_folder = './reports/logs'\n",
    "        log_cm_path = os.path.join(log_folder, 'cm')\n",
    "        cm_writer = tf.summary.create_file_writer(log_cm_path)\n",
    "        test_pred = self.model.predict(self.X_test)\n",
    "        # Calculate the confusion matrix using sklearn.metrics\n",
    "        cm = tfa.metrics.MultiLabelConfusionMatrix(\n",
    "            num_classes=(train_params.num_classes))(self.y_test,\n",
    "                                                    np.where(\n",
    "                                                        test_pred > 0.5, 1, 0))\n",
    "        figure = plot_confusion_matrix(cm, train_params.columns)\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with cm_writer.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:24.869465Z",
     "start_time": "2021-05-28T17:24:24.853133Z"
    }
   },
   "outputs": [],
   "source": [
    "def perf_grid(dataset, labels, columns, model, n_thresh=100):\n",
    "    \"\"\"Computes the performance table containing target, label names,\n",
    "    label frequencies, thresholds between 0 and 1, number of tp, fp, fn,\n",
    "    precision, recall and f-score metrics for each label.\n",
    "    \n",
    "    Args:\n",
    "        dataset (tf.data.Datatset): contains the features array\n",
    "        labels (numpy array): target matrix of shape (BATCH_SIZE, N_LABELS)\n",
    "        tags (list of strings): column names in target matrix\n",
    "        model (tensorflow keras model): model to use for prediction\n",
    "        n_thresh (int) : number of thresholds to try\n",
    "        \n",
    "    Returns:\n",
    "        grid (Pandas dataframe): performance table \n",
    "    \"\"\"\n",
    "\n",
    "    # Get predictions\n",
    "    y_hat_val = model.predict(dataset)\n",
    "    # Define target matrix\n",
    "    y_val = np.array(labels)\n",
    "    # Find label frequencies in the validation set\n",
    "    label_freq = np.array(labels).sum(axis=0)\n",
    "    # Get label indexes\n",
    "    label_index = [i for i in range(len(columns))]\n",
    "    # Define thresholds\n",
    "    thresholds = np.linspace(0, 1, n_thresh + 1).astype(np.float32)\n",
    "\n",
    "    # Compute all metrics for all labels\n",
    "    ids, labels, freqs, tps, fps, fns, precisions, recalls, f1s = [], [], [], [], [], [], [], [], []\n",
    "    for l in label_index:\n",
    "        for thresh in thresholds:\n",
    "            ids.append(l)\n",
    "            labels.append(columns[l])\n",
    "            freqs.append(round(label_freq[l] / len(y_val), 2))\n",
    "            y_hat = y_hat_val[:, l]\n",
    "            y = y_val[:, l]\n",
    "            y_pred = y_hat > thresh\n",
    "            tp = np.count_nonzero(y_pred * y)\n",
    "            fp = np.count_nonzero(y_pred * (1 - y))\n",
    "            fn = np.count_nonzero((1 - y_pred) * y)\n",
    "            precision = tp / (tp + fp + 1e-16)\n",
    "            recall = tp / (tp + fn + 1e-16)\n",
    "            f1 = tp / (tp + (fn + fp) * 0.5 + 1e-16)\n",
    "            tps.append(tp)\n",
    "            fps.append(fp)\n",
    "            fns.append(fn)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "\n",
    "    # Create the performance dataframe\n",
    "    grid = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'label': np.array(labels),\n",
    "        'freq': freqs,\n",
    "        'threshold': list(thresholds) * len(label_index),\n",
    "        'tp': tps,\n",
    "        'fp': fps,\n",
    "        'fn': fns,\n",
    "        'precision': precisions,\n",
    "        'recall': recalls,\n",
    "        'f1': f1s\n",
    "    })\n",
    "\n",
    "    grid = grid[[\n",
    "        'id', 'label', 'freq', 'threshold', 'tp', 'fn', 'fp', 'precision',\n",
    "        'recall', 'f1'\n",
    "    ]]\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:26.195496Z",
     "start_time": "2021-05-28T17:24:26.184112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modified versions of functions implemented by Ashref Maiza\n",
    "def learning_curves(history, version):\n",
    "    \"\"\"Plot the learning curves of loss and macro f1 score \n",
    "    for the training and validation datasets.\n",
    "    \n",
    "    Args:\n",
    "        history: history callback of fitting a tensorflow keras model \n",
    "    \"\"\"\n",
    "    path_assets = './reports/assets/{}'.format(version)\n",
    "    mkdir(path_assets)\n",
    "    title_loss = 'Training and Validation Loss - Model {}'.format(version)\n",
    "    title_f1_score = 'Training and Validation Categorical Accuracy - Model {}'.format(\n",
    "        version)\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    categorical_accuracy = history.history['categorical_accuracy']\n",
    "    val_categorical_accuracy = history.history['val_categorical_accuracy']\n",
    "\n",
    "    epochs = len(loss)\n",
    "\n",
    "    style.use(\"bmh\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(range(1, epochs + 1), loss, label='Training Loss')\n",
    "    plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title_loss)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('./reports/assets/{}/{}.png'.format(version, title_loss))\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(range(1, epochs + 1),\n",
    "             categorical_accuracy,\n",
    "             label='Training categorical accuracy')\n",
    "    plt.plot(range(1, epochs + 1),\n",
    "             val_categorical_accuracy,\n",
    "             label='Validation categorical accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Categorical accuracy')\n",
    "    plt.title(title_f1_score)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./reports/assets/{}/{}.png'.format(version, title_f1_score))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return loss, val_loss, categorical_accuracy, val_categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:26.590262Z",
     "start_time": "2021-05-28T17:24:26.579778Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, columns):\n",
    "    fig = plt.figure(figsize=(10, 20))\n",
    "    for i, (label, matrix) in enumerate(zip(columns, cm)):\n",
    "        ax = plt.subplot(6, 3, i + 1)\n",
    "        labels = [f'not_{label}', label]\n",
    "        sns.heatmap(matrix,\n",
    "                    ax=ax,\n",
    "                    annot=True,\n",
    "                    square=True,\n",
    "                    fmt='.0f',\n",
    "                    cbar=False,\n",
    "                    cmap='Blues',\n",
    "                    xticklabels=labels,\n",
    "                    yticklabels=labels,\n",
    "                    linecolor='black',\n",
    "                    linewidth=1)\n",
    "        plt.title(labels[1], size=8)\n",
    "        plt.subplots_adjust(wspace=5, hspace=5)\n",
    "        ax.set_yticklabels(labels, va='center', position=(0, 0.28), size=8)\n",
    "        ax.set_xticklabels(labels, ha='center', position=(0.28, 0), size=8)\n",
    "        plt.xlabel('PREDICTED CLASS', labelpad=10)\n",
    "        plt.ylabel('TRUE CLASS', labelpad=10)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T17:24:29.614176Z",
     "start_time": "2021-05-28T17:24:29.608662Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "\n",
    "    buf = BytesIO()\n",
    "\n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "\n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "\n",
    "    return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
